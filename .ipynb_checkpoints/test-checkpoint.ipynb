{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e5e8e9",
   "metadata": {},
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, we integrate the newly tested scene generator with the dual-chatbot system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb17e8ce",
   "metadata": {},
   "source": [
    "#### 1. Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c5fa0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI, AzureChatOpenAI\n",
    "from langchain.llms import OpenAI, AzureOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate, \n",
    "    MessagesPlaceholder, \n",
    "    SystemMessagePromptTemplate, \n",
    "    HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.chains import ConversationChain\n",
    "import utilities\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcfb79e",
   "metadata": {},
   "source": [
    "#### 2. Problem definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c387ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_type_list = [\"classification\", \"regression\", \"clustering\",\n",
    "                    \"anomaly detection\", \"recommendation\", \"time series analysis\",\n",
    "                    \"natural language processing\", \"computer vision\"]\n",
    "business_size_list = [\"small (less than 100 employees)\",\n",
    "                    \"Medium (100-500 employees)\",\n",
    "                    \"large (more than 500 employees)\"]\n",
    "industry_list = [\"healthcare\", \"finance\", \"retail\", \"technology\",\n",
    "                \"manufacturing\", \"transportation\", \"energy\",\n",
    "                \"real estate\", \"education\", \"government\", \"non-profit\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451f1d3c",
   "metadata": {},
   "source": [
    "#### 3. Generate scenarios\n",
    "\n",
    "To generate scenarios, we adopt a two-stage appraoch, where in the first stage, we prompt the LLM to generate a broad description of the scenario, and in the second stage, we prompt the LLM to fill the details for the previously generated scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15bbd09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scen_generator_llm = AzureChatOpenAI(openai_api_base=\"https://abb-chcrc.openai.azure.com/\",\n",
    "                        openai_api_version=\"2023-03-15-preview\",\n",
    "                        openai_api_key=os.environ[\"OPENAI_API_KEY_AZURE\"],\n",
    "                        openai_api_type=\"azure\",\n",
    "                        deployment_name=\"gpt-35-turbo-0301\",\n",
    "                        temperature=1.0)\n",
    "# scen_generator = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1436f169",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"\"\"{input}\"\"\")\n",
    "])\n",
    "\n",
    "scen_generator = ConversationChain(memory=memory, prompt=prompt, \n",
    "                                  llm=scen_generator_llm, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1fd3510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem description: A medium-sized manufacturing company specializes in producing electronic components for various industries. Recently, the quality control team has detected an increasing number of anomalies in the production process, resulting in defective products that need costly recalls and unsatisfied customers. The company suspects that these anomalies are caused by the malfunctioning of some of the machines involved in the production process.\n",
      "\n",
      "Desired outcome: The company wants to identify the root cause(s) of the anomaly occurrences and take corrective actions to minimize costly recalls and disruptions in production. The data science project should aim to develop a predictive model that can detect anomalies early and precisely, as well as a dashboard that can provide real-time monitoring of the production process.\n",
      "\n",
      "Available data: \n",
      "1. Production logs: The data recorded by the machines in the production process, including sensor measurement data, machine status, timestamps, and other relevant information. \n",
      "2. Maintenance records: The maintenance and repair records of the machines, including the parts replaced, the repair tasks performed, the date and time of the maintenance, and the technicians involved. \n",
      "3. Quality control data: The data collected by the quality control team, including the number and types of defects detected, the time and location of the detection, and the outcome of the investigation.\n",
      "\n",
      "Note: The data scientist needs to preprocess and integrate these data sources, perform exploratory data analysis, and apply appropriate anomaly detection techniques to identify the anomaly patterns. The project also needs to involve the collaboration of domain experts, such as the machine technicians, production supervisors, and quality control professionals, to ensure the validity and feasibility of the detected anomalies and the proposed corrective actions.\n"
     ]
    }
   ],
   "source": [
    "# Generate description of the scenario\n",
    "industry = \"manufacturing\"\n",
    "business_size = \"medium\"\n",
    "problem_type = \"anomaly detection\"\n",
    "details = \"Types of products manufactured, machines used in the production process, \\\n",
    "common issues faced by the company, tools and technologies used for quality control.\"\n",
    "\n",
    "# Prompt\n",
    "prompt = f\"\"\"For a {industry} company of {business_size} size focusing on {problem_type} problems, \n",
    "generate a concrete data science project scenario that a data scientist might encounter in real life. \n",
    "Please provide concrete and specific details relevant to the selected industry and problem type.\n",
    "\n",
    "For the generated scenario, please provide:\n",
    "1. A specific and realistic description of a problem faced by the company.\n",
    "2. The desired outcome that the company is hoping to achieve by solving the problem.\n",
    "3. A list of the top 3 most relevant data sources that might be available for solving the problem.\n",
    "\n",
    "Output format:\n",
    "Problem description: [content of problem description]\n",
    "Desired outcome: [content of desired outcome]\n",
    "Available data: [content of available data]\n",
    "\"\"\"\n",
    "\n",
    "interm_scenario = scen_generator.predict(input=prompt)\n",
    "print(interm_scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cae1f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enriched problem description: A medium-sized manufacturing company produces electronic components for automotive, health and beauty, and home appliance industries. The production process involves multiple machines, including CNC machines, robotics arms, and a pick and place machine to mention a few. The company has been facing issues with defects in the final products, including faulty components, irregular sizes, and inadequate finishing. Quality control is done manually by the team, which can result in human errors and missed defects. The company has invested in traditional quality control tools such as Statistical Process Control (SPC) and Failure Mode and Effect Analysis (FEMA) but is still struggling to curb the defects.\n",
      "\n",
      "Desired outcome: The company is looking to reduce the waste produced, minimize recalls, and improve customer satisfaction. The data science project aims to develop a predictive model that can detect anomalies in real-time. Furthermore, a dashboard can provide insights into the production process, representing the machine's performance metrics, and allow the team to take corrective measures.\n",
      "\n",
      "Available data:\n",
      "1. Machine logs: Machine sensor data that provides information on temperature, humidity, pressure, and other relevant metrics.\n",
      "2. Maintenance records: Records about the regular maintenance schedule, tasks performed, the time spent, and the machine practitioner.\n",
      "3. Quality control data: Data on the manually conducted inspection of the final products. There is also data from the automated vision system to detect defects, as well as factory data such as different workers involved in production at different stages.\n",
      "\n",
      "Note: The data scientist's task consists of analyzing data from the different sources, identifying patterns, and implementing appropriate anomaly detection mechanisms. The project must incorporate the efforts of the domain experts to provide a holistic understanding of the underlying problem and ensure the model's validity in real-world conditions.\n"
     ]
    }
   ],
   "source": [
    "# Prompt\n",
    "additional_details = f\"\"\"Based on the previously generated scenario, please enrich the problem description \n",
    "by providing more specific details (such as {details}) about the problem.\n",
    "\n",
    "Output format:\n",
    "Enriched problem description: [content of enriched problem description]\n",
    "Desired outcome: [content of desired outcome]\n",
    "Available data: [content of available data]\n",
    "\"\"\"\n",
    "\n",
    "scenario = scen_generator.predict(input=additional_details)\n",
    "print(scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bb913e",
   "metadata": {},
   "source": [
    "#### 4. Define two chatbots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cbd43f",
   "metadata": {},
   "source": [
    "Client bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8744b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientBot():\n",
    "    \"\"\"Class definition for the client bot, created with LangChain.\"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, engine):\n",
    "        \"\"\"Setup journalist bot.\n",
    "        \"\"\"   \n",
    "        if engine == 'OpenAI':\n",
    "            self.llm = ChatOpenAI(\n",
    "                model_name='gpt-3.5-turbo',\n",
    "                temperature=0.8\n",
    "            )\n",
    "\n",
    "        elif engine == 'Azure':\n",
    "            self.llm = AzureChatOpenAI(openai_api_base=\"https://abb-chcrc.openai.azure.com/\",\n",
    "                    openai_api_version=\"2023-03-15-preview\",\n",
    "                    openai_api_key=os.environ[\"OPENAI_API_KEY_AZURE\"],\n",
    "                    openai_api_type=\"azure\",\n",
    "                    deployment_name=\"gpt-35-turbo-0301\",\n",
    "                    temperature=0.8)\n",
    "\n",
    "        else:\n",
    "            raise KeyError(\"Currently unsupported chat model type!\")\n",
    "            \n",
    "        # Instantiate memory\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "        \n",
    "    def instruct(self, industry, business_size, scenario):\n",
    "        \"\"\"Determine the context of client chatbot. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.industry = industry\n",
    "        self.business_size = business_size\n",
    "        self.scenario = scenario\n",
    "        \n",
    "        # Define prompt template\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(self._specify_system_message()),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"\"\"{input}\"\"\")\n",
    "        ])\n",
    "        \n",
    "        # Create conversation chain\n",
    "        self.conversation = ConversationChain(memory=self.memory, prompt=prompt, \n",
    "                                              llm=self.llm, verbose=False)\n",
    "        \n",
    "\n",
    "    def step(self, prompt):\n",
    "        \"\"\"Client chatbot speaks. \n",
    "        \"\"\"\n",
    "        response = self.conversation.predict(input=prompt)\n",
    "        \n",
    "        return response\n",
    "        \n",
    "\n",
    "    def _specify_system_message(self):\n",
    "        \"\"\"Specify the behavior of the client chatbot.\n",
    "        \"\"\"      \n",
    "        \n",
    "        # Prompt\n",
    "        prompt = f\"\"\"You are role-playing a representative from a {self.industry} company of {self.business_size} size and \n",
    "        you are meeting with a data scientist (which is played by another bot), to discuss how to leverage machine learning \n",
    "        to address a problem your company is facing. \n",
    "        \n",
    "        The problem description, desired outcome, and available data are:\n",
    "        {self.scenario}.\n",
    "        \n",
    "        Your ultimate goal is to work with the data scientist to define a clear problem and agree on a suitable data science solution or approach.\n",
    "\n",
    "        Guidelines to keep in mind:\n",
    "        - **Get Straight to the Point**: Start the conversation by directly addressing the problem at hand. There is no need for pleasantries or introductions.\n",
    "        - **Engage in Conversation**: Respond to the data scientist's questions and prompts. Do not provide all the information at once or provide the entire conversation yourself.\n",
    "        - **Clarify and Confirm**: Always make sure to clarify and confirm the problem, desired outcome, and any proposed solutions with the data scientist. \n",
    "        - **Stay in Role**: Your role as a client is to represent your company's needs and work with the data scientist to define a clear problem and agree on a suitable data science solution or approach. Do not try to propose solutions.\n",
    "        - **Provide Information as Needed**: Provide information about the problem, available data, constraints, and requirements as it becomes relevant in the conversation. If the data scientist asks a question and the information was not provided in the problem description, it is okay to improvise and create details that seem reasonable.\n",
    "        - **Collaborate**: Collaborate with the data scientist to clearly define the problem and to consider any proposed solutions or approaches.\n",
    "        \"\"\"\n",
    "\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db53a750",
   "metadata": {},
   "source": [
    "Data scientist bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6840d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataScientistBot():\n",
    "    \"\"\"Class definition for the data scientist bot, created with LangChain.\"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self, engine):\n",
    "        \"\"\"Setup journalist bot.\n",
    "        \"\"\"        \n",
    "        if engine == 'OpenAI':\n",
    "            self.llm = ChatOpenAI(\n",
    "                model_name='gpt-3.5-turbo',\n",
    "                temperature=0.8\n",
    "            )\n",
    "\n",
    "        elif engine == 'Azure':\n",
    "            self.llm = AzureChatOpenAI(openai_api_base=\"https://abb-chcrc.openai.azure.com/\",\n",
    "                    openai_api_version=\"2023-03-15-preview\",\n",
    "                    openai_api_key=os.environ[\"OPENAI_API_KEY_AZURE\"],\n",
    "                    openai_api_type=\"azure\",\n",
    "                    deployment_name=\"gpt-35-turbo-0301\",\n",
    "                    temperature=0.8)\n",
    "\n",
    "        else:\n",
    "            raise KeyError(\"Currently unsupported chat model type!\")\n",
    "            \n",
    "        # Instantiate memory\n",
    "        self.memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "        \n",
    "    def instruct(self, industry, business_size, scenario):\n",
    "        \"\"\"Determine the context of data scientist chatbot. \n",
    "        \"\"\"\n",
    "        \n",
    "        self.industry = industry\n",
    "        self.business_size = business_size\n",
    "        self.problem_type = problem_type\n",
    "        \n",
    "        # Define prompt template\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            SystemMessagePromptTemplate.from_template(self._specify_system_message()),\n",
    "            MessagesPlaceholder(variable_name=\"history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"\"\"{input}\"\"\")\n",
    "        ])\n",
    "        \n",
    "        # Create conversation chain\n",
    "        self.conversation = ConversationChain(memory=self.memory, prompt=prompt, \n",
    "                                              llm=self.llm, verbose=False)\n",
    "        \n",
    "\n",
    "    def step(self, prompt):\n",
    "        \"\"\"Data scientist chatbot speaks. \n",
    "        \"\"\"\n",
    "        response = self.conversation.predict(input=prompt)\n",
    "        \n",
    "        return response\n",
    "        \n",
    "\n",
    "    def _specify_system_message(self):\n",
    "        \"\"\"Specify the behavior of the data scientist chatbot.\n",
    "        \"\"\"      \n",
    "        \n",
    "        # Prompt\n",
    "        prompt = f\"\"\"You are role-playing a data scientist meeting with a representative (which is played by another chatbot) \n",
    "        from a {self.industry} company of {self.business_size} size. They are currently concerned with \n",
    "        a {self.problem_type} problem.\n",
    "\n",
    "        Your ultimate goal is to understand the problem in depth and agree on a suitable data science solution or approach \n",
    "        by engaging in a conversation with the client representative. \n",
    "\n",
    "        Guidelines to keep in mind:\n",
    "        - **Engage in Conversation**: You are only the data scientist. Do not provide the entire conversation yourself.\n",
    "        - **Understand the Problem**: Make sure to ask questions to get a clear and detailed understanding of the problem, the desired outcome, available data, constraints, and requirements.\n",
    "        - **Propose Solutions**: Based on the information provided by the client, suggest possible data science approaches or solutions to address the problem.\n",
    "        - **Consider Constraints**: Be mindful of any constraints that the client may have, such as budget, timeline, or data limitations, and tailor your proposed solutions accordingly.\n",
    "        - **Collaborate**: Collaborate with the client to refine the problem definition, proposed solutions, and ultimately agree on a suitable data science approach.\n",
    "        \"\"\"\n",
    "\n",
    "        return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a6c200",
   "metadata": {},
   "source": [
    "#### 5. Simulate the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "315a3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two chatbots\n",
    "client = ClientBot('Azure')\n",
    "data_scientist = DataScientistBot('Azure')\n",
    "\n",
    "# Specify instructions\n",
    "client.instruct(industry, business_size, scenario)\n",
    "data_scientist.instruct(industry, business_size, problem_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "697d30ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👨‍💼 Client: Hello, thank you for taking the time to meet with me. We are a manufacturing company that produces electronic components for the automotive, health and beauty, and home appliance industries. We have been facing issues with defects in the final products, including faulty components, irregular sizes, and inadequate finishing. The quality control is done manually by the team, which can result in human errors and missed defects. We have invested in traditional quality control tools such as Statistical Process Control (SPC) and Failure Mode and Effect Analysis (FEMA) but still struggling to curb the defects. We are hoping to work with a data scientist to develop a predictive model that can detect anomalies in real-time, in order to reduce the waste produced, minimize recalls, and improve customer satisfaction. We have some data available that we hope can be useful in developing this model.\n",
      "👩‍💻 Data Scientist: Hello, thank you for providing an overview of the problem, it helps me to understand the issue at hand. Could you tell me more about the data that you have available? What type of data is it, and how is it collected? Also, do you have any historical data or is it all real-time?\n",
      "\n",
      "\n",
      "\n",
      "👨‍💼 Client: We have three types of data that we think will be useful for this project:\n",
      "\n",
      "1. Machine logs: This data is collected from sensors on the machines and provides information on temperature, humidity, pressure, and other relevant metrics. \n",
      "\n",
      "2. Maintenance records: We have records about the regular maintenance schedule, tasks performed, the time spent, and the machine practitioner. \n",
      "\n",
      "3. Quality control data: We have data on the manually conducted inspection of the final products. There is also data from the automated vision system to detect defects, as well as factory data such as different workers involved in production at different stages. \n",
      "\n",
      "We have historical data available as well as real-time data. The historical data includes data from the past year, and we collect new data every minute.\n",
      "👩‍💻 Data Scientist: Thank you for sharing the details about the data. It sounds like you have a variety of relevant data types available. Before proposing any specific solutions, I'd like to ask a few questions to help me better understand the problem.\n",
      "\n",
      "1. Can you provide more details on the nature of the anomalies or defects you're trying to detect? Are there any particular types of defects that occur more frequently than others?\n",
      "2. What is the desired outcome of the predictive model? For example, do you want the model to output a binary classification to indicate whether a product is defective or not, or would you like to have a severity score for defects identified?\n",
      "3. Are there any specific constraints or limitations that we should consider, such as budget or timelines, or limitations on the data that can be used?\n",
      "\n",
      "\n",
      "\n",
      "👨‍💼 Client: 1. The anomalies and defects we are trying to detect include faulty components, irregular sizes, and inadequate finishing. These are the most frequently occurring types of defects that we have noticed during our manual quality control checks.\n",
      "\n",
      "2. The desired outcome of the predictive model is to detect anomalies in real-time, so that the production team can take corrective action before defective components are produced. We would like to have a binary classification output to indicate whether a product is defective or not.\n",
      "\n",
      "3. We do have a budget and timeline to consider for this project. We would also like to consider the feasibility of implementing the solution in our production environment. As for the data, we believe that the data we have provided should be sufficient for the project, but we are open to considering additional data sources if they can be useful in developing the model.\n",
      "👩‍💻 Data Scientist: Thank you for clarifying that. \n",
      "\n",
      "Based on the information provided, I would suggest considering a supervised machine learning approach using the available data to develop a predictive model. Specifically, I would recommend using an anomaly detection algorithm to detect potential defects in real-time. \n",
      "\n",
      "Given the data types available, I would suggest exploring the use of a multi-modal deep learning approach. This approach would involve training a deep neural network to learn from the various data sources (machine logs, maintenance records, and quality control data) to identify anomalous patterns. \n",
      "\n",
      "Another approach worth exploring is the use of unsupervised machine learning methods such as clustering or anomaly detection algorithms. These algorithms can learn from the data to identify patterns that are different from the normal patterns. This can potentially help detect anomalies in real-time.\n",
      "\n",
      "I would recommend reviewing the data and exploring the feasibility, limitations, and cost of implementing these different approaches. It's important to ensure that the solution can be integrated into your production environment and that it meets your budget and timeline needs. \n",
      "\n",
      "Would you be interested in exploring these approaches further?\n",
      "\n",
      "\n",
      "\n",
      "👨‍💼 Client: Thank you for your suggestions. We are interested in exploring these approaches further. We would like to know more about how these approaches work and the specific steps needed to implement them in our production environment. Specifically, we would like to know how much data would be required to develop the model, what performance metrics we should consider, and what are the expected timelines and costs associated with each approach.\n",
      "👩‍💻 Data Scientist: Great! I can provide some more information on each approach and answer your questions regarding implementation.\n",
      "\n",
      "1. Multi-modal deep learning approach:\n",
      "- This approach involves developing a deep neural network that uses multiple data sources (machine logs, maintenance records, and quality control data) to detect anomalies in real-time.\n",
      "- To implement this approach, we would need to first preprocess and clean the data, and then split it into training and testing sets. Typically, a large amount of labeled data is required to train a deep neural network effectively. However, we can explore transfer learning techniques that can leverage pre-trained models and smaller amounts of labeled data to improve performance.\n",
      "- The performance of the model can be evaluated using metrics such as precision, recall, F1 score, and accuracy. We could also consider using the receiver operating characteristic (ROC) curve to evaluate the trade-off between true positive and false positive rates.\n",
      "- The timelines and costs associated with this approach depend on the complexity of the model and the amount of data required. Typically, training a deep neural network could take several days to several weeks. The costs associated with this approach would include the data preprocessing and cleaning, the development of the model, and the necessary hardware and software resources.\n",
      "\n",
      "2. Unsupervised machine learning approach:\n",
      "- This approach involves using clustering or anomaly detection algorithms to identify anomalous patterns in the data without labels.\n",
      "- To implement this approach, we would need to first preprocess and clean the data, and then apply the clustering or anomaly detection algorithm. This approach typically requires less labeled data and could be more suitable if there is less training data available.\n",
      "- The performance of the model can be evaluated using metrics such as silhouette score, homogeneity, and completeness for clustering, and precision, recall, and F1 score for anomaly detection.\n",
      "- The timelines and costs associated with this approach depend on the complexity and type of algorithm used. Clustering algorithms are typically faster to execute than anomaly detection algorithms. The costs associated with this approach would include the data preprocessing and cleaning, and the development of the model.\n",
      "\n",
      "In terms of the amount of data required, it would depend on the complexity of the model and the approach used. As a general rule of thumb, more data would lead to better model performance. However, it's important to consider the feasibility and cost of collecting and labeling large amounts of data.\n",
      "\n",
      "I hope this information helps. Let me know if you have any further questions or concerns.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👨‍💼 Client: Thank you for providing detailed information regarding the approaches. Based on the information provided, we think that the multi-modal deep learning approach would be more suitable for our needs because we have a reasonable amount of labeled data, and we believe that the neural network could learn from the data to identify anomalies in real-time. However, we would like to consider the feasibility of implementing the solution in our production environment before making a final decision. We also would like to know more about the pre-processing and cleaning of data and the performance metrics used to evaluate the model. Can you provide more details about those?\n",
      "👩‍💻 Data Scientist: Sure, I can provide more information.\n",
      "\n",
      "For the pre-processing and cleaning of data, we would perform the following steps:\n",
      "\n",
      "1. Data Cleaning: We would remove any irrelevant or inconsistent data, handle any missing values, and correct any data entry errors.\n",
      "\n",
      "2. Feature Engineering: We would extract relevant features from the different data sources, such as statistical summaries, time-series features, or frequency-domain features. This helps to reduce the dimensionality of the data and improve model performance.\n",
      "\n",
      "3. Data Normalization: We would normalize the data to ensure that the features are on the same scale. This step is important for deep learning models because they are sensitive to the scale of the input features.\n",
      "\n",
      "4. Data Splitting: We would split the data into training, validation, and testing sets. The training set is used to train the model, while the validation set is used to tune the hyperparameters and prevent overfitting. The testing set is used to evaluate the performance of the final model.\n",
      "\n",
      "For the performance metrics, we typically use a combination of classification metrics and receiver operating characteristic (ROC) curves to evaluate the performance of the model. Some of the commonly used metrics are:\n",
      "\n",
      "1. Accuracy: measures the proportion of correctly classified samples.\n",
      "\n",
      "2. Precision: measures the proportion of true positives out of the total predicted positives.\n",
      "\n",
      "3. Recall: measures the proportion of true positives out of the total actual positives.\n",
      "\n",
      "4. F1 Score: combines precision and recall into a single metric.\n",
      "\n",
      "We would also use ROC curves to evaluate the trade-off between true positive rate (TPR) and false positive rate (FPR) by varying the decision threshold of the model.\n",
      "\n",
      "Regarding the feasibility of implementing the solution in your production environment, we would need to consider factors such as the infrastructure and resources required to run the model, the availability of data in real-time, and the integration with your existing systems. The hardware and software requirements would depend on the complexity of the model and the size of the data. We would work with your team to ensure that the model is deployed in a way that meets your needs and constraints.\n",
      "\n",
      "Let me know if you have any further questions or concerns.\n",
      "\n",
      "\n",
      "\n",
      "👨‍💼 Client: Thank you for providing more information. We think that the multi-modal deep learning approach will be suitable for our needs, and we will work with your team to ensure that the model is deployed in a way that meets our needs and constraints. We appreciate your expertise and support in this project.\n",
      "👩‍💻 Data Scientist: You're welcome, and I'm glad that we could help. We are excited to work with you on this project and help you achieve your goals. If you have any questions or concerns along the way, please do not hesitate to reach out. Let's get started!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Book-keeping\n",
    "question_list = []\n",
    "answer_list = []\n",
    "\n",
    "# Start conversation\n",
    "for i in range(6):\n",
    "    if i == 0:\n",
    "        question = client.step('Start the conversation')\n",
    "    else:\n",
    "        question = client.step(answer)\n",
    "    question_list.append(question)\n",
    "    print(\"👨‍💼 Client: \" + question)\n",
    "    \n",
    "    answer = data_scientist.step(question)\n",
    "    answer_list.append(answer)\n",
    "\n",
    "    print(\"👩‍💻 Data Scientist: \" + answer)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53996f4",
   "metadata": {},
   "source": [
    "#### 6. Summarizer\n",
    "\n",
    "The objective of summarizer is to condense the conversation rounds between the client bot and data scientist bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff986dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer_llm = AzureOpenAI(\n",
    "                    deployment_name=\"deployment-5af509f3323342ee919481751c6f8b7d\",\n",
    "                    model_name=\"text-davinci-003\",\n",
    "                    openai_api_base=\"https://abb-chcrc.openai.azure.com/\",\n",
    "                    openai_api_version=\"2023-03-15-preview\",\n",
    "                    openai_api_key=os.environ[\"OPENAI_API_KEY_AZURE\"],\n",
    "                    openai_api_type=\"azure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6022cdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Please concisely summarize the following segment of a conversation between a client and \n",
    "a data scientist discussing a potential data science project:\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"conversation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "674d5818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1/6th conversation round.\n",
      "Processing 2/6th conversation round.\n",
      "Processing 3/6th conversation round.\n",
      "Processing 4/6th conversation round.\n",
      "Processing 5/6th conversation round.\n",
      "Processing 6/6th conversation round.\n"
     ]
    }
   ],
   "source": [
    "# Loop over individual rounds\n",
    "conversation_summary = []\n",
    "for i, (q, a) in enumerate(zip(question_list, answer_list)):\n",
    "    print(f\"Processing {i+1}/{len(question_list)}th conversation round.\")\n",
    "    \n",
    "    # Compile one round of conversation\n",
    "    conversation_round = ''\n",
    "    conversation_round += 'Client: ' + q + '\\n\\n'\n",
    "    conversation_round += 'Data scientist: ' + a\n",
    "\n",
    "    response = summarizer_llm.predict(prompt.format(conversation=conversation_round))\n",
    "    conversation_summary.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcc5ecd",
   "metadata": {},
   "source": [
    "#### 7. Analyst\n",
    "\n",
    "The objective of the analyst bot is to examine the conversation between the client and data scientist bot, and provide feedback on the strategy adopted by the data scientist bot for problem defining and scoping, as well as indicate potential area for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4db41e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst_llm = AzureOpenAI(\n",
    "                    deployment_name=\"deployment-5af509f3323342ee919481751c6f8b7d\",\n",
    "                    model_name=\"text-davinci-003\",\n",
    "                    openai_api_base=\"https://abb-chcrc.openai.azure.com/\",\n",
    "                    openai_api_version=\"2023-03-15-preview\",\n",
    "                    openai_api_key=os.environ[\"OPENAI_API_KEY_AZURE\"],\n",
    "                    openai_api_type=\"azure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5b3c866",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a senior data scientist who has been asked to review a conversation between a data scientist \n",
    "and a client from a {industry} company of {business_size} size, focusing on a {problem_type} problem. \n",
    "The client and data scientist are discussing how to define and scope a data science project to address the problem.\n",
    "\n",
    "Please provide an assessment of the conversation, focusing on the strategy adopted by the data scientist to \n",
    "define and scope the problem, any potential room for improvement, and any other key points you think are important.\n",
    "Please organize your response with nicely formatted bulletpoints.\n",
    "\n",
    "Here is the conversation: \n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"industry\", \"business_size\", \"problem_type\", \"conversation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "66c3011a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assessment: \n",
      "- The data scientist has adopted an effective strategy to define and scope the problem by providing detailed information on each approach, including the amount of data required, metrics to evaluate performance, expected timelines and costs, and the feasibility and cost of collecting and labeling large amounts of data.\n",
      "- The data scientist has demonstrated knowledge and expertise in the domain of anomaly detection and has provided the client with a potential solution using a multi-modal deep learning approach. \n",
      "- The data scientist has taken into account the client's constraints and needs, offering their expertise and support, and welcoming the client's questions and concerns.\n",
      "- The data scientist has provided information on the pre-processing and cleaning of data, performance metrics to evaluate the model, as well as the hardware and software requirements, data availability in real-time, and the integration with existing systems.\n",
      "- There is room for improvement in terms of discussing potential risks and limitations of the proposed solution, as well as the need to consider the ethical implications of the model.\n"
     ]
    }
   ],
   "source": [
    "analysis = analyst_llm.predict(prompt.format(industry=industry,\n",
    "                                            business_size=business_size,\n",
    "                                            problem_type=problem_type,\n",
    "                                            conversation=' '.join(conversation_summary)))\n",
    "print(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e96c45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
